# Problem description
Use LDA to find the projection vector that best separates the three classes, project the data and reduce it to 1D. Sample for class:  
* X1 = (x,y) = (2, 3), (3, 6), (4, 4), (4, 2), (2, 4)  
* X2 = (x,y) = (6, 8), (9, 5), (9, 10), (8, 7), (10, 8)  
* X3 = (x,y) = (23, 14), (15, 8), (17, 12), (19, 10), (22, 9)  
  
# Solution
  
Original data (markers represent the mean (black overall mean)):    
<p align="center">
	<img src="https://raw.githubusercontent.com/Dzvezdana/machine-learning-and-data-science/master/LDA/original_data.jpg">  
</p>
  
Projected data:  
<p align="center">  
	<img src="https://raw.githubusercontent.com/Dzvezdana/machine-learning-and-data-science/master/LDA/projected_data.jpg">  
</p>
  
Projection vector:   
<p align="center">
	<img src="https://raw.githubusercontent.com/Dzvezdana/machine-learning-and-data-science/master/LDA/projection_vector.jpg">  
</p>
  
Data with reduced dimension:       
<p align="center">
	<img src="https://raw.githubusercontent.com/Dzvezdana/machine-learning-and-data-science/master/LDA/reduced_dimension.jpg">  
</p>